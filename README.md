Linear Regression score: 0.37890204979043074
Decision Tree score: 0.8889609613037851
KMeans score: 0.9918473564970515 
The linear regression score was low, indicating that it is unreasonable to use this algorithm for this data.
Decision trees were better at dealing with missing data than other models. There were some deficiencies or parts that needed to be cleaned in our data, the decision trees coped with these situations better and their score was quite high.
The KMeans clustering algorithm fits numerical data very well because this algorithm uses mathematical distances, such as the Euclidean distance, to measure the distances between data. This gives effective results, especially in data sets containing numerical variables.KMeans is used to find natural segments or clusters in the data set. For example, it grouped variables such as house prices or square meter values ​​according to their similarities. KMeans creates similar groups by bringing together houses with similar features among this numerical data.
Looking at the results obtained, it appears that the model can successfully predict in KMeans and Decision Tree algorithms.
Kaggle link: https://www.kaggle.com/code/mertmesti/machine-learning-project/notebook
